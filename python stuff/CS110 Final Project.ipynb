{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def trim(year):\n",
    "    with open(f'{year}.json') as json_file:  \n",
    "        data = json.load(json_file)\n",
    "        states = data['features']\n",
    "\n",
    "        for s in states:\n",
    "            if s['geometry']['type'] == 'MultiPolygon':\n",
    "                s['geometry']['coordinates']=s['geometry']['coordinates'][0][0]\n",
    "            else:\n",
    "                s['geometry']['coordinates']=s['geometry']['coordinates'][0]\n",
    "\n",
    "    with open(f'{year}.json', 'w') as outfile:  \n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class LinkedVertex:\n",
    "    def __init__(self, crd, prev = None, nxt = None,src = None):\n",
    "        self.src = src\n",
    "        self.crd = crd\n",
    "        self.prev = prev\n",
    "        self.nxt = nxt\n",
    "        \n",
    "def verticesEQ(v1,v2):\n",
    "    return v1[0]==v2[0] and v1[1] == v2[1]\n",
    "\n",
    "\n",
    "class LinkedVertexHash:\n",
    "    def __init__(self,buckets = 2500000):\n",
    "        self.els = [None]*buckets\n",
    "        self.buckets = buckets\n",
    "        self.size = 0\n",
    "    \n",
    "    def items(self):\n",
    "        for b in self.els: \n",
    "            if b:\n",
    "                for el in b:\n",
    "                    yield el\n",
    "                    \n",
    "    def contains(self,el):\n",
    "        h = self.vHash(el)\n",
    "        if self.els[h]:\n",
    "            for v in self.els[h]:\n",
    "                if verticesEQ(el,v.crd):\n",
    "                    return v\n",
    "        return False\n",
    "                    \n",
    "    def add(self,el):\n",
    "        if self.contains(el.crd):\n",
    "            return \n",
    "        \n",
    "        self.size+=1\n",
    "        h = self.vHash(el.crd)        \n",
    "        \n",
    "        if self.els[h] == None:\n",
    "            self.els[h] = [el]\n",
    "        else:\n",
    "            self.els[h] += [el]\n",
    "            \n",
    "    def addPoly(self,items,src=None):\n",
    "        crds = items \n",
    "            \n",
    "        prev = None\n",
    "        for v in crds:\n",
    "            newVertex = LinkedVertex(crd = v, prev = prev, nxt = None,src = src)\n",
    "            self.add(newVertex)\n",
    "\n",
    "            if prev == None:\n",
    "                first = newVertex\n",
    "            else:     \n",
    "                prev.nxt = newVertex\n",
    "\n",
    "            prev = newVertex\n",
    "\n",
    "        newVertex.nxt = first\n",
    "        first.prev = newVertex\n",
    "            \n",
    "    def remove(self,el):\n",
    "        h = self.vHash(el.crd)\n",
    "        if self.els[h]:\n",
    "            for i,v in enumerate(self.els[h]):\n",
    "                if verticesEQ(el,v.crd):\n",
    "                    self.els[h].pop(i)\n",
    "                    self.size-=1\n",
    "                    return   \n",
    "        raise f'self set does not contain {el}'\n",
    "    \n",
    "    def vHash(self,v):\n",
    "        p = 53\n",
    "        return int((v[0]*(p)+v[1]*(p**2)))%self.buckets\n",
    "    \n",
    "    def asList(self):\n",
    "        res = []\n",
    "        \n",
    "        for b in self.els:\n",
    "            if b:\n",
    "                res+=b\n",
    "                \n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def union(s1,s2):\n",
    "        res = LinkedVertexHash()\n",
    "        \n",
    "        for i in s1.items():\n",
    "            res.add(i)\n",
    "            \n",
    "        for i in s2.items():\n",
    "            res.add(i)\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def intersection(s1,s2):\n",
    "        res = LinkedVertexHash()\n",
    "        \n",
    "        for i in s1.items():\n",
    "            if s2.contains(i.crd):\n",
    "                res.add(i)\n",
    "                \n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def difference(s1,s2):\n",
    "        res = copy.deepcopy(s1)\n",
    "        its = LinkedVertexHash.intersection(s1,s2)\n",
    "        \n",
    "        for i in its.items():\n",
    "            res.remove(i)\n",
    "            \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setFromJSON(data):\n",
    "    states = data['features']\n",
    "    \n",
    "    vSize = 0\n",
    "    for s in states:\n",
    "        vSize += len(s['geometry']['coordinates'])\n",
    "    \n",
    "    vSet = LinkedVertexHash(buckets = int(vSize*1.3))\n",
    "    \n",
    "    for i,s in enumerate(states):\n",
    "        crds = s['geometry']['coordinates']\n",
    "        vSet.addPoly(crds,i)\n",
    "        \n",
    "    return vSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1790.json') as json_file:  \n",
    "    data1790 = json.load(json_file)\n",
    "            \n",
    "with open('1880.json') as json_file:  \n",
    "    data1880 = json.load(json_file)\n",
    "\n",
    "with open('1840.json') as json_file:  \n",
    "    data1840 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def decompose(new, prev):\n",
    "    \n",
    "    prevSet = setFromJSON(prev)\n",
    "    newSet = setFromJSON(new)\n",
    "    \n",
    "    newStates = new['features']\n",
    "    compressedStates = []\n",
    "    for s in newStates:\n",
    "        crds = s['geometry']['coordinates']\n",
    "        vs = []\n",
    "        \n",
    "        en = iter(enumerate(crds))\n",
    "        count = 0\n",
    "        for i,c in en:\n",
    "            hook = prevSet.contains(c)\n",
    "            if hook:\n",
    "                record = [hook]\n",
    "                j = 0\n",
    "                line = hook.nxt\n",
    "                while (verticesEQ(crds[(i+j+1)%len(crds)], line.crd) and\n",
    "                        not verticesEQ(line.crd, hook.crd) and\n",
    "                        i+j < len(crds)):\n",
    "\n",
    "                    j+=1\n",
    "                    record += [line]\n",
    "                    line = line.nxt\n",
    "                count+=j\n",
    "                vs += [{'hook':hook.crd, 'length':j, 'src':hook.src}]\n",
    "                \n",
    "                next(islice(en,j ,j), None)\n",
    "                \n",
    "            else:\n",
    "                count+=1\n",
    "                vs += [c]\n",
    "        compressedStates.append(vs)\n",
    "    return compressedStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = data1880\n",
    "new = data1790\n",
    "\n",
    "compressed = decompose(new,prev)\n",
    "\n",
    "with open('compressed2.json', 'w') as outfile:  \n",
    "    json.dump({'states':compressed}, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
